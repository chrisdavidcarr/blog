[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I’m a LLM developer and data professional based in Cardiff, United Kingdom. Like the majority of data scientists, I write code in Python. That being said, I also have an interest in building with low-code tools (particularly n8n). I’m currently building a data analytics startup called Opinii.\nI’m also available for n8n projects (contact me on LinkedIn)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Setting Up LangSmith with a Dockerised n8n Instance\n\n\n\n\n\n\nn8n\n\n\nLangSmith\n\n\n\n\n\n\n\n\n\nMay 12, 2025\n\n\nChris Carr\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/langsmith-with-n8n-docker/index.html",
    "href": "posts/langsmith-with-n8n-docker/index.html",
    "title": "Setting Up LangSmith with a Dockerised n8n Instance",
    "section": "",
    "text": "Recently, I’ve been experimenting with using LangGraph to prototype LLM applications. While other observation tools exist (Arize Phoenix and MLflow, for example), LangChain’s own offering - LangSmith - is easy to set up and thus worth trying out.\nSince I’m still using n8n as part of my development flow, it makes sense to integrate LangSmith with my self-hosted n8n instance. This is supported in n8n since its AI Agent nodes use LangChain.js under the hood.\nI run a personal n8n instance on a DigitalOcean Droplet (using Docker Compose). It was set up using the instructions that can be found here.\nI’m documenting how I set it up since this I couldn’t find any instructions for integrating LangChain with this common installation pattern.\n\n\n\n\n\n\nImportant\n\n\n\nThis guide is for self-hosted n8n instances installed with Docker Compose. LangSmith integration is not currently supported in n8n Cloud."
  },
  {
    "objectID": "posts/langsmith-with-n8n-docker/index.html#get-langsmith-api-key",
    "href": "posts/langsmith-with-n8n-docker/index.html#get-langsmith-api-key",
    "title": "Setting Up LangSmith with a Dockerised n8n Instance",
    "section": "Get LangSmith API Key",
    "text": "Get LangSmith API Key\nIf you have not already done so, sign up for a LangSmith account. Note that there are two data regions to choose from - US and EU.\nIn LangSmith, select Set up tracing and then Generate API Key. Select the TypeScript environment variables and you should be able to see the following values: LANGSMITH_TRACING, LANGSMITH_ENDPOINT, LANGSMITH_API_KEY, LANGSMITH_PROJECT and OPENAI_API_KEY."
  },
  {
    "objectID": "posts/langsmith-with-n8n-docker/index.html#update-docker-compose-yaml-file",
    "href": "posts/langsmith-with-n8n-docker/index.html#update-docker-compose-yaml-file",
    "title": "Setting Up LangSmith with a Dockerised n8n Instance",
    "section": "Update Docker Compose YAML File",
    "text": "Update Docker Compose YAML File\nIn the command line of the server hosting your n8n, use the following commands to enter the directory containing n8n and open docker-compose.yml.\ncd n8n-docker-compose\nnano docker-compose.yml\nIn this file, we need to add the bottom four lines to the n8n environment subsection as shown below below . Make sure that the LANGSMITH_ENDPOINT matches the data centre that you’ve selected.\n\n\n\n\n\n\nNote\n\n\n\nAs of writing (May 2025), setting LANGSMITH_PROJECT doesn’t appear to work. However, setting LANGCHAIN_PROJECT does, so we’ll go with that.\n\n\nn8n:\n    image: docker.n8n.io/n8nio/n8n\n    restart: always\n    ports:\n        - 5678:5678\n    environment:\n        - N8N_HOST=${SUBDOMAIN}.${DOMAIN_NAME}\n        - N8N_PORT=5678\n        - N8N_PROTOCOL=https\n        - NODE_ENV=production\n        - WEBHOOK_URL=https://${SUBDOMAIN}.${DOMAIN_NAME}/\n        - GENERIC_TIMEZONE=${GENERIC_TIMEZONE}\n        - LANGSMITH_ENDPOINT=https://api.smith.langchain.com # add this (use https://eu.api.smith.langchain.com if using the EU data centre)\n        - LANGSMITH_API_KEY=PASTE-LANGSMITH-KEY-HERE # add this\n        - LANGSMITH_TRACING=true # add this\n        - LANGCHAIN_PROJECT=YOUR-PROJECT-NAME # add this\nSave and exit out of this file. Then restart n8n by using the following commands:\nsudo docker compose down\nsudo docker compose up -d"
  },
  {
    "objectID": "posts/langsmith-with-n8n-docker/index.html#verify-setup-has-been-successful",
    "href": "posts/langsmith-with-n8n-docker/index.html#verify-setup-has-been-successful",
    "title": "Setting Up LangSmith with a Dockerised n8n Instance",
    "section": "Verify Setup Has Been Successful",
    "text": "Verify Setup Has Been Successful\n\nOptional Check Using n8n Workflow\nI put together a small workflow that checks to see whether n8n has visibility of the environment variables that were just added. To use it, right-click and select Inspect and then Console (you’ll have to right-click somewhere on the page that isn’t the workflow canvas). Then run the workflow. If the setup has been successful, you’ll see the following printed in the console (with your values):\nn8n can see the environment variables! Check them below:\n\nLANGSMITH_API_KEY=YOUR-LANGSMITH-API-KEY\nLANGSMITH_TRACING=true\nLANGSMITH_ENDPOINT=YOUR-ENDPOINT\nLANGCHAIN_PROJECT=YOUR-PROJECT-NAME\n\n\nTest by Calling an AI Node in n8n\nCreate a workflow (or use an existing one) that uses an AI node (such as AI Agent). Run the workflow. In LangSmith, you will now be able to see the trace under the project name that you chose when setting the environment variables."
  }
]